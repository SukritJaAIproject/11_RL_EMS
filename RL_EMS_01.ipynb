{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL_EMS_01.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMYaxlC0jA4V9UKA22pQK8e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"N65RMAC-JBiV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596022059302,"user_tz":-420,"elapsed":1083,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}},"outputId":"7bd08d12-10a3-4e80-b96b-22f953d99e13"},"source":["try:\n","    from google.colab import drive\n","    %tensorflow_version 2.x\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Note: using Google CoLab\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sKZD5_AHJK0_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1596022080093,"user_tz":-420,"elapsed":21317,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}},"outputId":"26f56e2e-81bd-45af-bb45-aada5eb5f1a4"},"source":["if COLAB:\n","  !sudo apt-get install -y xvfb ffmpeg x11-utils\n","  !pip install -q 'gym==0.10.11'\n","  !pip install -q 'imageio==2.4.0'\n","  !pip install -q PILLOW\n","  !pip install -q 'pyglet==1.3.2'\n","  !pip install -q pyvirtualdisplay\n","  !pip install -q tf-agents"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","x11-utils is already the newest version (7.7+3build1).\n","ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n","xvfb is already the newest version (2:1.19.6-1ubuntu4.4).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-440\n","Use 'sudo apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KV6z-tqaJUq2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596022081563,"user_tz":-420,"elapsed":16054,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["import base64\n","import imageio\n","import IPython\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import PIL.Image\n","import pyvirtualdisplay\n","import math\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","from tf_agents.agents.ddpg import actor_network\n","from tf_agents.agents.ddpg import critic_network\n","from tf_agents.agents.ddpg import ddpg_agent\n","\n","from tf_agents.agents.dqn import dqn_agent\n","from tf_agents.drivers import dynamic_step_driver\n","from tf_agents.environments import suite_gym\n","from tf_agents.environments import tf_py_environment\n","from tf_agents.eval import metric_utils\n","from tf_agents.metrics import tf_metrics\n","from tf_agents.networks import q_network\n","from tf_agents.policies import random_tf_policy\n","from tf_agents.replay_buffers import tf_uniform_replay_buffer\n","from tf_agents.trajectories import trajectory\n","from tf_agents.trajectories import policy_step\n","from tf_agents.utils import common\n","\n","import gym\n","from gym import spaces\n","from gym.utils import seeding\n","from gym.envs.registration import register\n","import PIL.ImageDraw\n","import PIL.Image\n","from PIL import ImageFont"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7Or_UtYJoAz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596022254712,"user_tz":-420,"elapsed":942,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["# Set up a virtual display for rendering OpenAI gym environments.\n","vdisplay = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"uH552noWTecn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596022260925,"user_tz":-420,"elapsed":1808,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["class SimpleGameOfLifeEnv(gym.Env):\n","    metadata = {\n","        'render.modes': ['human', 'rgb_array'],\n","        'video.frames_per_second': 1\n","    }\n","\n","    STATE_ELEMENTS = 7\n","    STATES = ['age', 'salary', 'home_value', 'home_loan', 'req_home_pmt', \n","              'acct_tax_adv', 'acct_tax', \"expenses\", \"actual_home_pmt\", \"tax_deposit\", \n","              \"tax_adv_deposit\", \"net_worth\"]\n","    STATE_AGE = 0\n","    STATE_SALARY = 1\n","    STATE_HOME_VALUE = 2\n","    STATE_HOME_LOAN = 3\n","    STATE_HOME_REQ_PAYMENT = 4\n","    STATE_SAVE_TAX_ADV = 5\n","    STATE_SAVE_TAXABLE = 6\n","\n","    MEG = 1.0e6\n","\n","    ACTION_ELEMENTS = 4\n","    ACTION_HOME_LOAN = 0\n","    ACTION_SAVE_TAX_ADV = 1\n","    ACTION_SAVE_TAXABLE = 2\n","    ACTION_LUXURY = 3\n","\n","    INFLATION = (0.015)/12.0\n","    INTEREST = (0.05)/12.0\n","    TAX_RATE = (.142)/12.0\n","    EXPENSES = 0.6\n","    INVEST_RETURN = 0.065/12.0\n","    SALARY_LOW = 40000.0\n","    SALARY_HIGH = 60000.0\n","    START_AGE = 18\n","    RETIRE_AGE = 80\n","\n","    def __init__(self, goal_velocity=0):\n","      self.verbose = False\n","      self.viewer = None\n","\n","      self.action_space = spaces.Box(\n","          low=0.0,\n","          high=1.0,\n","          shape=(SimpleGameOfLifeEnv.ACTION_ELEMENTS,),\n","          dtype=np.float32\n","      )\n","      self.observation_space = spaces.Box(\n","          low=0,\n","          high=2,\n","          shape=(SimpleGameOfLifeEnv.STATE_ELEMENTS,),\n","          dtype=np.float32\n","      )\n","\n","      self.seed()\n","      self.reset()\n","\n","      self.state_log = []\n","\n","    def seed(self, seed=None):\n","        self.np_random, seed = seeding.np_random(seed)\n","        return [seed]\n","\n","    def _calc_net_worth(self):\n","      home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n","      principal = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n","      worth = home_value - principal\n","      worth += self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV]\n","      worth += self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE]\n","      return worth\n","\n","    def _eval_action(self, action, payment):\n","      # Calculate actions\n","      act_home_payment = action[SimpleGameOfLifeEnv.ACTION_HOME_LOAN]\n","      act_tax_adv_pay = action[SimpleGameOfLifeEnv.ACTION_SAVE_TAX_ADV]\n","      act_taxable = action[SimpleGameOfLifeEnv.ACTION_SAVE_TAXABLE]\n","      act_luxury = action[SimpleGameOfLifeEnv.ACTION_LUXURY]\n","      if payment <=0:\n","        act_home_payment = 0\n","      total_act = act_home_payment + act_tax_adv_pay + act_taxable + act_luxury + self.expenses\n","\n","      if total_act <1e-2:\n","        pct_home_payment = 0\n","        pct_tax_adv_pay = 0\n","        pct_taxable = 0\n","        pct_luxury = 0\n","      else:\n","        pct_home_payment = act_home_payment / total_act\n","        pct_tax_adv_pay = act_tax_adv_pay / total_act\n","        pct_taxable = act_taxable / total_act\n","        pct_luxury = act_luxury / total_act\n","\n","      return pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury\n","\n","    def step(self, action):\n","      self.last_action = action\n","      age = self.state[SimpleGameOfLifeEnv.STATE_AGE]\n","      salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]\n","      home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n","      principal = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n","      payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n","      net1 = self._calc_net_worth()\n","      remaining_salary = salary\n","\n","      # Calculate actions\n","      pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury = \\\n","        self._eval_action(action,payment)\n","\n","      # Expenses\n","      current_expenses = salary * self.expenses\n","      remaining_salary -= current_expenses\n","      if self.verbose:\n","        print(f\"Expenses: {current_expenses}\")\n","        print(f\"Remaining Salary: {remaining_salary}\")\n","\n","      # Tax advantaged deposit action\n","      my_tax_adv_deposit = min(salary * pct_tax_adv_pay, remaining_salary)\n","      my_tax_adv_deposit = min(my_tax_adv_deposit, \\\n","        self.year_tax_adv_deposit_left) # Govt CAP\n","      self.year_tax_adv_deposit_left -= my_tax_adv_deposit\n","      remaining_salary -= my_tax_adv_deposit\n","      tax_adv_deposit = my_tax_adv_deposit * 1.05 # Company match\n","      self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] += \\\n","        int(tax_adv_deposit)\n","\n","      if self.verbose:\n","        print(f\"IRA Deposit: {tax_adv_deposit}\")\n","        print(f\"Remaining Salary: {remaining_salary}\")\n","\n","      # Tax\n","      remaining_salary -= remaining_salary * SimpleGameOfLifeEnv.TAX_RATE\n","      if self.verbose:\n","        print(f\"Tax Salary: {remaining_salary}\")\n","\n","      # Home payment\n","      actual_payment = min(salary * pct_home_payment, remaining_salary)\n","\n","      if principal>0:\n","        ipart = principal * SimpleGameOfLifeEnv.INTEREST\n","        ppart = actual_payment - ipart\n","        principal = int(principal-ppart)\n","        if principal<=0:\n","          principal = 0\n","          self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = 0\n","        elif actual_payment < payment:\n","          self.late_count += 1\n","          if self.late_count>15:\n","            sell = (home_value-principal)/2\n","            sell -= 20000\n","            sell = max(sell,0)\n","            self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += sell\n","            principal = 0\n","            home_value = 0\n","            self.expenses += .3\n","            self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = 0\n","            if self.verbose:\n","              print(f\"Foreclosure!!\")\n","          else:\n","            late_fee = payment * 0.1\n","            principal += late_fee\n","            if self.verbose:\n","              print(f\"Late Fee: {late_fee}\")\n","\n","\n","        self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN] = principal\n","        remaining_salary -= actual_payment\n","\n","      if self.verbose:\n","        print(f\"Home Payment: {actual_payment}\")\n","        print(f\"Remaining Salary: {remaining_salary}\")\n","\n","      # Taxable savings\n","      actual_savings = remaining_salary * pct_taxable\n","      self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += actual_savings\n","      remaining_salary -= actual_savings\n","\n","      if self.verbose:\n","        print(f\"Tax Save: {actual_savings}\")\n","        print(f\"Remaining Salary (goes to Luxury): {remaining_salary}\")\n","\n","      # Investment income\n","      return_taxable = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] * \\\n","          self.invest_return\n","      return_tax_adv = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] * \\\n","          self.invest_return\n","\n","      return_taxable *= 1-SimpleGameOfLifeEnv.TAX_RATE\n","      self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += return_taxable\n","      self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] += return_tax_adv\n","\n","      # Yearly events\n","      if age>0 and age % 12 == 0:\n","        self.perform_yearly()\n","\n","      # Monthly events\n","      self.state[SimpleGameOfLifeEnv.STATE_AGE] += 1\n","      \n","      # Time to retire (by age?)\n","      done = self.state[SimpleGameOfLifeEnv.STATE_AGE] > \\\n","        (SimpleGameOfLifeEnv.RETIRE_AGE*12)\n","\n","      # Calculate reward \n","      net2 = self._calc_net_worth()\n","      reward = net2 - net1\n","\n","      # Track progress\n","      if self.verbose:\n","        print(f\"Networth: {nw}\")\n","        print(f\"*** End Step {self.step_num}: State={self.state}, \\\n","          Reward={reward}\")\n","      self.state_log.append(self.state + [current_expenses, actual_payment, \n","      actual_savings, my_tax_adv_deposit, net2])\n","      self.step_num += 1\n","\n","      # Normalize state and finish up\n","      norm_state = [x/SimpleGameOfLifeEnv.MEG for x in self.state]\n","      return norm_state, reward/SimpleGameOfLifeEnv.MEG, done, {}\n","\n","    def perform_yearly(self):\n","      salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]\n","      home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n","      \n","      self.inflation = SimpleGameOfLifeEnv.INTEREST + \\\n","          self.np_random.normal(loc=0,scale=1e-2)\n","      self.invest_return = SimpleGameOfLifeEnv.INVEST_RETURN + \\\n","          self.np_random.normal(loc=0,scale=1e-2)\n","\n","      self.year_tax_adv_deposit_left = 19000\n","      self.state[SimpleGameOfLifeEnv.STATE_SALARY] = \\\n","        int(salary * (1+self.inflation))\n","\n","      self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE] \\\n","        = int(home_value * (1+self.inflation))\n","\n","    def reset(self):\n","      self.expenses = SimpleGameOfLifeEnv.EXPENSES\n","      self.late_count = 0\n","      self.step_num = 0\n","      self.last_action = [0] * SimpleGameOfLifeEnv.ACTION_ELEMENTS\n","      self.state = [0] * SimpleGameOfLifeEnv.STATE_ELEMENTS\n","      self.state_log = []\n","      salary = float(self.np_random.randint(low=SimpleGameOfLifeEnv.SALARY_LOW,\n","                               high=SimpleGameOfLifeEnv.SALARY_HIGH))\n","      house_mult = self.np_random.uniform(low=1.5,high=4)\n","      value = round(salary*house_mult)\n","      p = (value*0.9)\n","      i = SimpleGameOfLifeEnv.INTEREST\n","      n = 30 * 12\n","      m = float(int(p *  ( i * (1 + i)**n ) / ( (1 + i)**n - 1)))\n","      self.state[SimpleGameOfLifeEnv.STATE_AGE] = \\\n","        SimpleGameOfLifeEnv.START_AGE * 12\n","      self.state[SimpleGameOfLifeEnv.STATE_SALARY] = salary / 12.0\n","      self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE] = value\n","      self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN] = p\n","      self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = m\n","      self.year_tax_adv_deposit_left = 19000\n","      self.perform_yearly()\n","      return np.array(self.state)\n","\n","    def render(self, mode='human'):\n","        screen_width = 600\n","        screen_height = 400\n","\n","        img = PIL.Image.new('RGB', (600, 400))\n","        d = PIL.ImageDraw.Draw(img)\n","        font = ImageFont.load_default()\n","        y = 0\n","        _, height = d.textsize(\"W\", font)\n","  \n","        age = self.state[SimpleGameOfLifeEnv.STATE_AGE]\n","        salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]*12\n","        home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n","        home_loan = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n","        home_payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n","        balance_tax_adv = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV]\n","        balance_taxable = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE]\n","        net_worth = self._calc_net_worth()\n","\n","        d.text((0, y), f\"Age: {age/12}\", fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Salary: {salary:,}\", fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Home Value: {home_value:,}\", fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Home Loan: {home_loan:,}\", fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Home Payment: {home_payment:,}\", fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Balance Tax Adv: {balance_tax_adv:,}\", \\\n","               fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Balance Taxable: {balance_taxable:,}\", \\\n","               fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Net Worth: {net_worth:,}\", fill=(0, 255, 0))\n","        y+=height*2\n","\n","        payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n","        pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury = \\\n","          self._eval_action(self.last_action,payment)\n","        d.text((0, y), f\"Percent Home Payment: {pct_home_payment}\", \\\n","               fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Percent Tax Adv: {pct_tax_adv_pay}\", fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Percent Taxable: {pct_taxable}\", fill=(0, 255, 0))\n","        y+=height\n","        d.text((0, y), f\"Percent Luxury: {pct_luxury}\", fill=(0, 255, 0))\n","\n","        return np.array(img)\n","\n","    def close(self):\n","        pass"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"8w3hVIN00peQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596022293798,"user_tz":-420,"elapsed":764,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["register(\n","    id='simple-game-of-life-v0',\n","    entry_point=f'{__name__}:SimpleGameOfLifeEnv',\n",")"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nziTDvd_WsBs","colab_type":"text"},"source":["Testing the Environment"]},{"cell_type":"code","metadata":{"id":"vW8ENASxV4Hg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596023219501,"user_tz":-420,"elapsed":2650,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}},"outputId":"a33bd435-a479-4fde-9b23-d650f5ff817d"},"source":["env_name = 'simple-game-of-life-v0'\n","env = gym.make(env_name)\n","\n","env.reset()\n","done = False\n","\n","i = 0\n","env.verbose = False\n","while not done:\n","    i += 1\n","    #if i>36: break\n","    # ACTION_HOME_LOAN = 0, ACTION_SAVE_TAX_ADV = 1, ACTION_SAVE_TAXABLE = 2\n","    # ACTION_LUXURY = 3\n","    state, reward, done, _ = env.step([1,1,0,0])\n","    env.render()\n","    \n","env.close()\n","print(env._calc_net_worth())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["11277167.571338987\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tzdNH-L8Yw3Y","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","df = pd.DataFrame(env.state_log, columns=SimpleGameOfLifeEnv.STATES)\n","df = df.round(0)\n","df['age'] = df['age']/12\n","df['age'] = df['age'].round(2)\n","for col in df.columns:\n","  df[col] = df[col].apply(lambda x : \"{:,}\".format(x))\n","\n","pd.set_option('display.max_columns', 7)\n","pd.set_option('display.max_rows', 12)\n","display(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K4XEQLMAdyv9","colab_type":"text"},"source":["Hyperparameters"]},{"cell_type":"code","metadata":{"id":"DtuKIEx4dzfc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596024381337,"user_tz":-420,"elapsed":872,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["# How long should training run?\n","num_iterations = 50000 \n","# How many initial random steps, before training start, to\n","# collect initial data.\n","initial_collect_steps = 1000   \n","# How many steps should we run each iteration to collect \n","# data from.\n","collect_steps_per_iteration = 50\n","# How much data should we store for training examples.\n","replay_buffer_max_length = 100000\n","\n","batch_size = 64  \n","#learning_rate = 1e-4 \n","# How often should the program provide an update.\n","log_interval = 2500  \n","\n","# How many episodes should the program use for each evaluation.\n","num_eval_episodes = 100\n","# How often should an evaluation occur.\n","eval_interval = 5000"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jwH_WCK3drjw","colab_type":"text"},"source":["Instanciate the Environment"]},{"cell_type":"code","metadata":{"id":"pcQYzLBJZmv7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596024401304,"user_tz":-420,"elapsed":983,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["env_name = 'simple-game-of-life-v0'\n","#env_name = 'MountainCarContinuous-v0'\n","env = suite_gym.load(env_name)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0z5ynYz9Z3ip","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":417},"executionInfo":{"status":"ok","timestamp":1596024542220,"user_tz":-420,"elapsed":801,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}},"outputId":"f7579d09-ad9e-4d09-d881-ebaf170abf9e"},"source":["env.reset()\n","PIL.Image.fromarray(env.render())"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<PIL.Image.Image image mode=RGB size=600x400 at 0x7F9263D0BA58>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"hOR-dOR4edCY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596024609483,"user_tz":-420,"elapsed":864,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["train_py_env = suite_gym.load(env_name)\n","eval_py_env = suite_gym.load(env_name)\n","\n","train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n","eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cXfG65Oetc2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596025857645,"user_tz":-420,"elapsed":10758,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["actor_fc_layers=(400, 300)\n","critic_obs_fc_layers=(400,)\n","critic_action_fc_layers=None\n","critic_joint_fc_layers=(300,)\n","ou_stddev=0.2\n","ou_damping=0.15\n","target_update_tau=0.05\n","target_update_period=5\n","dqda_clipping=None\n","td_errors_loss_fn=tf.compat.v1.losses.huber_loss\n","gamma=0.995\n","reward_scale_factor=1.0\n","gradient_clipping=None\n","\n","actor_learning_rate=1e-4\n","critic_learning_rate=1e-3\n","debug_summaries=False\n","summarize_grads_and_vars=False\n","\n","global_step = tf.compat.v1.train.get_or_create_global_step()\n","\n","actor_net = actor_network.ActorNetwork(\n","        train_env.time_step_spec().observation,\n","        train_env.action_spec(),\n","        fc_layer_params=actor_fc_layers,\n","    )\n","\n","critic_net_input_specs = (train_env.time_step_spec().observation,\n","                          train_env.action_spec())\n","\n","critic_net = critic_network.CriticNetwork(\n","    critic_net_input_specs,\n","    observation_fc_layer_params=critic_obs_fc_layers,\n","    action_fc_layer_params=critic_action_fc_layers,\n","    joint_fc_layer_params=critic_joint_fc_layers,\n",")\n","\n","tf_agent = ddpg_agent.DdpgAgent(\n","    train_env.time_step_spec(),\n","    train_env.action_spec(),\n","    actor_network=actor_net,\n","    critic_network=critic_net,\n","    actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n","        learning_rate=actor_learning_rate),\n","    critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n","        learning_rate=critic_learning_rate),\n","    ou_stddev=ou_stddev,\n","    ou_damping=ou_damping,\n","    target_update_tau=target_update_tau,\n","    target_update_period=target_update_period,\n","    dqda_clipping=dqda_clipping,\n","    td_errors_loss_fn=td_errors_loss_fn,\n","    gamma=gamma,\n","    reward_scale_factor=reward_scale_factor,\n","    gradient_clipping=gradient_clipping,\n","    debug_summaries=debug_summaries,\n","    summarize_grads_and_vars=summarize_grads_and_vars,\n","    train_step_counter=global_step)\n","tf_agent.initialize()"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhfA8NTboMC7","colab_type":"text"},"source":["\n","## Metrics and Evaluation"]},{"cell_type":"code","metadata":{"id":"chvXDVUZoM_d","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596027109486,"user_tz":-420,"elapsed":1519,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["def compute_avg_return(environment, policy, num_episodes=10):\n","\n","  total_return = 0.0\n","  for _ in range(num_episodes):\n","\n","    time_step = environment.reset()\n","    episode_return = 0.0\n","\n","    while not time_step.is_last():\n","      action_step = policy.action(time_step)\n","      time_step = environment.step(action_step.action)\n","      episode_return += time_step.reward\n","    total_return += episode_return\n","\n","  avg_return = total_return / num_episodes\n","  return avg_return.numpy()[0]\n","\n","\n","# See also the metrics module for standard implementations of different metrics.\n","# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0Xg9nK7oIzf","colab_type":"text"},"source":["## Data Collection"]},{"cell_type":"code","metadata":{"id":"dWf5r_2Vjbww","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596027120445,"user_tz":-420,"elapsed":1480,"user":{"displayName":"Sukrit Jaidee","photoUrl":"","userId":"00184606200318469354"}}},"source":["def collect_step(environment, policy, buffer):\n","  time_step = environment.current_time_step()\n","  action_step = policy.action(time_step)\n","  next_time_step = environment.step(action_step.action)\n","  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n","\n","  # Add trajectory to the replay buffer\n","  buffer.add_batch(traj)\n","\n","def collect_data(env, policy, buffer, steps):\n","  for _ in range(steps):\n","    collect_step(env, policy, buffer)\n","\n","random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n","                                                train_env.action_spec())\n","\n","replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n","    data_spec=tf_agent.collect_data_spec,\n","    batch_size=train_env.batch_size,\n","    max_length=replay_buffer_max_length)\n","\n","collect_data(train_env, random_policy, replay_buffer, steps=100)\n","\n","# Dataset generates trajectories with shape [Bx2x...]\n","dataset = replay_buffer.as_dataset(\n","    num_parallel_calls=3, \n","    sample_batch_size=batch_size, \n","    num_steps=2).prefetch(3)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nLM9qgIIoY80","colab_type":"text"},"source":["## Training the agent"]},{"cell_type":"code","metadata":{"id":"avP2_cOTmpnH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"21ad8d92-1e2c-4a54-a090-d8c2cbb215af"},"source":["iterator = iter(dataset)\n","\n","# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n","tf_agent.train = common.function(tf_agent.train)\n","\n","# Reset the train step\n","tf_agent.train_step_counter.assign(0)\n","\n","# Evaluate the agent's policy once before training.\n","avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n","returns = [avg_return]\n","\n","for _ in range(num_iterations):\n","\n","  # Collect a few steps using collect_policy and save to the replay buffer.\n","  for _ in range(collect_steps_per_iteration):\n","    collect_step(train_env, tf_agent.collect_policy, replay_buffer)\n","\n","  # Sample a batch of data from the buffer and update the agent's network.\n","  experience, unused_info = next(iterator)\n","  train_loss = tf_agent.train(experience).loss\n","\n","  step = tf_agent.train_step_counter.numpy()\n","\n","  if step % log_interval == 0:\n","    print('step = {0}: loss = {1}'.format(step, train_loss))\n","\n","  if step % eval_interval == 0:\n","    avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n","    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n","    returns.append(avg_return)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["step = 2500: loss = 0.0001917575573315844\n","step = 5000: loss = 0.002398618496954441\n","step = 5000: Average Return = 7.930449962615967\n","step = 7500: loss = 0.0006469473009929061\n","step = 10000: loss = 0.00041416112799197435\n","step = 10000: Average Return = 6.872987747192383\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rVSyiZ6oocjr","colab_type":"code","colab":{}},"source":["iterations = range(0, num_iterations + 1, eval_interval)\n","plt.plot(iterations, returns)\n","plt.ylabel('Average Return')\n","plt.xlabel('Iterations')\n","plt.ylim(top=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qAdv5gjlpbZc","colab_type":"text"},"source":["Videos"]},{"cell_type":"code","metadata":{"id":"rQhzA48EpcVj","colab_type":"code","colab":{}},"source":["def embed_mp4(filename):\n","  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n","  video = open(filename,'rb').read()\n","  b64 = base64.b64encode(video)\n","  tag = '''\n","  <video width=\"640\" height=\"480\" controls>\n","    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n","  Your browser does not support the video tag.\n","  </video>'''.format(b64.decode())\n","\n","  return IPython.display.HTML(tag)\n","\n","def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n","  filename = filename + \".mp4\"\n","  with imageio.get_writer(filename, fps=fps) as video:\n","    for _ in range(num_episodes):\n","      time_step = eval_env.reset()\n","      video.append_data(eval_py_env.render())\n","      while not time_step.is_last():\n","        action_step = policy.action(time_step)\n","        time_step = eval_env.step(action_step.action)\n","        video.append_data(eval_py_env.render())\n","  return embed_mp4(filename)\n","\n","create_policy_eval_video(tf_agent.policy, \"trained-agent\")"],"execution_count":null,"outputs":[]}]}